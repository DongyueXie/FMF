<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Dongyue Xie" />

<meta name="date" content="2019-10-15" />

<title>Empirical Bayes Multiscale Poisson Matrix Factorization</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">SMF</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/DongyueXie/SMF">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Empirical Bayes Multiscale Poisson Matrix Factorization</h1>
<h4 class="author">Dongyue Xie</h4>
<h4 class="date">2019-10-15</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2019-10-17
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 1 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>SMF/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.4.0). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges" class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown file has unstaged changes. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomDongyueXieFMFtreedded0dd4138676aaf4a22b332382c4c9e998972dtargetblankdded0dda"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/DongyueXie/FMF/tree/dded0dd4138676aaf4a22b332382c4c9e998972d" target="_blank">dded0dd</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomDongyueXieFMFtreedded0dd4138676aaf4a22b332382c4c9e998972dtargetblankdded0dda" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/
    Ignored:    analysis/.DS_Store

Untracked files:
    Untracked:  analysis/EMMPMF.aux
    Untracked:  analysis/EMMPMF.log
    Untracked:  analysis/EMMPMF.out
    Untracked:  analysis/EMMPMF.pdf
    Untracked:  analysis/EMMPMF.synctex.gz
    Untracked:  analysis/EMMPMF.tex
    Untracked:  analysis/SmoothPMF.Rmd

Unstaged changes:
    Modified:   analysis/BMPMF.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the R Markdown and HTML files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view them.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/DongyueXie/FMF/32334245045352e92838364f3fffa74aadb81af9/docs/BMPMF.html" target="_blank">3233424</a>
</td>
<td>
Dongyue Xie
</td>
<td>
2019-10-17
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/DongyueXie/FMF/blob/31c115eddbc149a792c25e29ff98fd5744246d27/analysis/BMPMF.Rmd" target="_blank">31c115e</a>
</td>
<td>
Dongyue Xie
</td>
<td>
2019-10-17
</td>
<td>
wflow_publish(“analysis/BMPMF.Rmd”)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/DongyueXie/FMF/582f35fad02e08b87a3122377da4ecd40e4837da/docs/BMPMF.html" target="_blank">582f35f</a>
</td>
<td>
Dongyue Xie
</td>
<td>
2019-10-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/DongyueXie/FMF/blob/24858357338f3ba2b9a369d62b0757f1279ef195/analysis/BMPMF.Rmd" target="_blank">2485835</a>
</td>
<td>
Dongyue Xie
</td>
<td>
2019-10-16
</td>
<td>
wflow_publish(“analysis/BMPMF.Rmd”)
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/DongyueXie/FMF/0d143b80bcb379f1be8b0aab72b00c8db641e32b/docs/BMPMF.html" target="_blank">0d143b8</a>
</td>
<td>
Dongyue Xie
</td>
<td>
2019-10-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/DongyueXie/FMF/blob/ceae2fcb19ce334259e1dd3a65978328536b6736/analysis/BMPMF.Rmd" target="_blank">ceae2fc</a>
</td>
<td>
Dongyue Xie
</td>
<td>
2019-10-16
</td>
<td>
wflow_publish(“analysis/BMPMF.Rmd”)
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>


<p>Suppose we observe a Poisson sequence <span class="math inline">\(X\in R^n\)</span>, <span class="math inline">\(n=2^S\)</span> and <span class="math inline">\(X_i\sim Poisson(\lambda_i)\)</span>. A Haar wavelet like decomposition of <span class="math inline">\(X\)</span> is defined as follows. Let <span class="math inline">\(s = 0,1,...,S-1\)</span> denote scale and <span class="math inline">\(l = 0,1,..., 2^s-1\)</span> denote location. <span class="math inline">\(X\)</span> follows a recursive dyadic partition(RDP): <span class="math display">\[X_{S,l} = X_{kl},\]</span> <span class="math display">\[X_{s,l} = X_{s+1,2l}+X_{s+1,2l+1}.\]</span></p>
<p>Similarly, RDP also holds for <span class="math inline">\(\lambda\)</span>.</p>
<p>Define <span class="math display">\[R_{s,l} = \frac{\lambda_{s+1,2l}}{\lambda_{s,l}},\]</span> then <span class="math display">\[X_{s+1,2l}|X_{s,l},R_{s,l}\sim Binomial(X_{s,l},R_{s,l}).\]</span></p>
<p>This multiscale decomposition reparameterizes <span class="math inline">\(\lambda\)</span> to <span class="math inline">\(\mu:=\lambda_{0,0}\)</span> and <span class="math inline">\(R:=\{R\}_{s,l}\)</span></p>
<p>Following this decomposition, the likelihood of <span class="math inline">\(X\)</span> is <span class="math display">\[\begin{equation}
    p(X|\lambda) = \prod_{i=0}^{n-1} p(X_i|\lambda_i) = p(X_{0,0}|\mu)\times \prod_{s=0}^{S-1}\prod_{l=0}^{2^s-1} p(X_{s+1,2l}|X_{s,l},R_{s,l}).
\end{equation}\]</span></p>
<p>Further we put priors on <span class="math inline">\(\lambda_{0,0}\)</span> and <span class="math inline">\(R_{s,l}\)</span>: <span class="math inline">\(\mu\sim g_\mu(\cdot)\)</span> and <span class="math inline">\(R_{s,l}\sim g_{R_s}(\cdot)\)</span>.</p>
<p>An empirical procedure first estimates <span class="math inline">\(g_\mu(\cdot)\)</span> and <span class="math inline">\(g_{R_s}(\cdot)\)</span> by maximizing the marginal likelihood, then obtains posterior <span class="math inline">\(p(R,\mu|X,\hat{g})\)</span>.</p>
<p><span class="math display">\[\begin{equation}
    \begin{split}
        \log p(X|g_\mu,g_R) &amp; = \E_{q_Rq_\mu}\log p(X|g_\mu,g_R)
        \\ &amp; = \E_{q_Rq_\mu}\log \frac{p(X,\mu,R|g_\mu,g_R)}{p(R,\mu|X,g_\mu,g_R)}
        \\ &amp; = \E_{q_Rq_\mu}(\log\frac{p(X,\mu,R|g_\mu,g_R)}{q_Rq_\mu}+\log\frac{q_Rq_\mu}{p(R,\mu|X,g_\mu,g_R)})
        \\ &amp; = \E_{q_Rq_\mu}\log p(X|R,\mu) + \E_{q_Rq_\mu}\log \frac{g_\mu g_R}{q_Rq_\mu} + KL(q_Rq_\mu||p(R,\mu|g_\mu,g_R))
        \\ &amp; = \mathcal{F}(q_R,q_\mu,g_\mu,g_R; X) + KL(q_Rq_\mu||p(R,\mu|g_\mu,g_R))
        \\ &amp; \geq \mathcal{F}(q_R,q_\mu,g_\mu,g_R; X).
    \end{split}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}\label{elboPS}
\begin{split}
    \mathcal{F}(q_R,q_\mu,g_\mu,g_R; X) &amp;= \E_{q_Rq_\mu}(\sum_{s=0}^{S-1}\sum_{l=0}^{2^s-1}\log p(X_{s+1,2l}|X_{s,l},R_{s,l})+\log p(X_{0,0}|\mu,c)) 
    \\ &amp; + \E_{q_R}\log\frac{g_R}{q_R} + \E_{q_\mu}\log\frac{g_\mu}{q_\mu}.
\end{split}
\end{equation}\]</span></p>

<p>Let <span class="math inline">\(Z_{ij}\sim Poisson(l_if_j)\)</span>, <span class="math inline">\(i=1,2,...,N\)</span>, <span class="math inline">\(j=1,2,...,p\)</span>. Priors: <span class="math inline">\(l\sim g_l(\cdot)\)</span>. Assume <span class="math inline">\(f\in R^p\)</span> has RDP defined in section 1 and <span class="math inline">\(R_{s,l}\sim g_{R_{s}}(\cdot)\)</span>, <span class="math inline">\(\mu\sim g_\mu(\cdot)\)</span>.</p>
<p>Using variational method, the evidence lower bound(ELBO) is <span class="math display">\[\begin{equation}\label{elbo}
\begin{split}
    ELBO &amp;= \E_q\log p(Z,l,R,\mu|g_l,g_\mu,g_R) - \E_q\log q(l,R,\mu)
    \\&amp;= \E_q \log p(Z|l,R,\mu) + \E_q\log\frac{g_l}{q_l} + \E_q\log\frac{g_R}{q_R} + \E_q\log\frac{g_\mu}{q_\mu}
\end{split}
\end{equation}\]</span></p>
<ol style="list-style-type: decimal">
<li>Update <span class="math inline">\(q_R, g_R,q_\mu,g_\mu\)</span>: given <span class="math inline">\(q_l,g_l\)</span>, <span class="math display">\[\begin{equation}\label{elboR}
\begin{split}
 ELBO(q_R, g_R) &amp;  = \E_q(\sum_{i=1}^N\sum_{s=0}^{S-1}\sum_{l=1}^{2^s-1}\log p(Z_{i,s+1,2l}|Z_{i,s,l},R_{s,l})+\sum_{i=1}^N\log 
 p(Z_{i,0,0}|\mu,l_i) )
 \\ &amp;  + \E_q\log\frac{g_R}{q_R} + \E_q\log\frac{g_\mu}{q_\mu} + Constant
\end{split}
\end{equation}\]</span></li>
</ol>
<p>This first line of ELBO in () is <span class="math display">\[\begin{equation}\label{elboR1}
\begin{split}
    \sum_s\sum_l \E_{q_R q_\mu,g_R, g_\mu}( (\Sigma_i Z_i)_{s+1,2l}\log R_{s,l} + (\Sigma_i Z_i)_{s+1,2l+1}\log (1-R_{s,l})  \\
   + \sum_i Z_{i,0,0}\log\mu -\mu\sum_i \E_{q_l}l_i )+ Constant
\end{split}
\end{equation}\]</span></p>
<p>Combine (), () and (), and compare with (), we can conclude that updating <span class="math inline">\(q_R, g_R,q_\mu,g_\mu\)</span> in rank-1 case is equivalent to solve Empirical Bayes Multiscale Poisson Smoothing with sequence <span class="math inline">\(\sum_i Z_i\)</span> and an extra scale factor <span class="math inline">\(c = \sum_i \E_{q_l} l_i\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>Update <span class="math inline">\(q_l,g_l\)</span>: given <span class="math inline">\(q_R, g_R,q_\mu,g_\mu\)</span>,</li>
</ol>
<p>We can write <span class="math inline">\(f_{j} = \mu\prod_{s=0}^{S-1} (R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)}\)</span>, where <span class="math inline">\(\epsilon_j(s) = 1\)</span> if the <span class="math inline">\(j\)</span>th element of <span class="math inline">\(f\)</span> goes to left children node at scale <span class="math inline">\(s\)</span>, and <span class="math inline">\(s(j)\)</span> is the location of <span class="math inline">\(j\)</span>th element of <span class="math inline">\(f\)</span> at scale <span class="math inline">\(s\)</span>.</p>
<p>Intuitively, this should be equivalent to solve EBPM with sequence <span class="math inline">\(\sum_j Z_j\)</span> and a scale factor <span class="math inline">\(\E_{q_\mu}(\mu)\sum_j \prod_s \E_{q_{R_s}}((R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)})\)</span>. The derivations below show the equivalence.</p>
<p>ELBO for rank-1 case:</p>
<p><span class="math display">\[\begin{equation}\label{elbol}
\begin{split}
ELBO(q_l,g_l) &amp; = \E_{q_R q_\mu q_l} \sum_{i}\sum_j(Z_{ij}\log(l_i\mu\prod_s (R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)})
\\ &amp; - l_i \mu \prod_s (R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)} ) + \E_q\log\frac{g_l}{q_l} + C_1
\\ &amp; = \E_{q_l}(\sum_i (\sum_j Z_{ij}\log l_i - l_i \E_{q_R q_\mu}\sum_j(\mu\prod_{s=0}^{S-1} (R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)})) + \E_q\log\frac{g_l}{q_l} + C_2.
\end{split}
\end{equation}\]</span></p>
<p>Solve Empirical Bayes Poisson mean given sequence <span class="math inline">\(\sum_j Z_j\)</span> and a scale factor <span class="math inline">\(f_j = \E_{q_\mu}(\mu)\sum_j \prod_s \E_{q_{R_s}}((R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)})\)</span>:</p>
<p><span class="math display">\[\begin{equation}\label{ebpml}
\begin{split}
\E_{q_l}\log p(\sum_jZ_j|l,f_j)  &amp; = \E_{q_l} \sum_i (\sum_jZ_j \log l_i - l_if_j)  + C_1
\\&amp;=  \E_{q_l} \sum_i (\sum_jZ_j \log l_i - l_i\times  \E_{q_\mu}(\mu)\sum_j \prod_s \E_{q_{R_s}}((R_{s,s(j)})^{\epsilon_j(s)}(1-R_{s,s(j)})^{1-\epsilon_j(s)})  + C_1
\\
\mathcal{F}(q_l,g_l)  &amp; = \E_{q_l}\log p(\sum_jZ_j|l,f_j)  + \E_q\log\frac{g_l}{q_l} + C_1
\end{split}
\end{equation}\]</span></p>
<p>The equivalence holds since <span class="math inline">\(ELBO(q_l,g_l)\)</span> and <span class="math inline">\(\mathcal{F}(q_l,g_l)\)</span> are equivalent.</p>

<p><span class="math display">\[\begin{equation}
    \begin{split}
        X = \sum_k Z_k ,
        \\
        Z_k\sim Poisson(l_k f_k^T), l_k\in R^N, f_k\in R^p,
        \\
        f_{kj} = \mu_{k}\prod_{s=0}^{S-1} (R_{k,s,s(j)})^{\epsilon_j(s)}(1-R_{k,s,s(j)})^{1-\epsilon_j(s)},
        \\
        l_k\sim g_{l_k}(\cdot),
        \\
        R_{k,s}\sim g_{R_{k,s}}(\cdot),
        \\
        \mu_k\sim g_{\mu_k}(\cdot),
    \end{split}
\end{equation}\]</span></p>
<p>Factorization of joint distribution is <span class="math display">\[\begin{equation}
    p(X,Z,L,R,\mu|g) = p(X|Z)p(Z|L,R,\mu)p(R|g_R)p(\mu|g_\mu)p(L|g_L).
\end{equation}\]</span></p>
<p>Goal is to estimate <span class="math inline">\(g\)</span> and obtain posterior <span class="math inline">\(p(L,R,\mu|X,\hat{g})\)</span>. Two ways to derive variational lower bound: Jensen’s Inequality and KL divergence.</p>
<p>Variational lower bound: <span class="math display">\[\begin{equation}\label{elbok}
\begin{split}
 \mathcal{F}(q,g) &amp; = \E_q \log p(X,Z,L,R,\mu|g)-\E_q\log q(Z,L,R,\mu)
 \\&amp;=\E_{q}\log p(X,Z,R,L,\mu|g_R,g_\mu,g_L)-\E_{q_L}\log q_L(L) - \E_{q_R}\log q_R(R) - \E_{q_Z}\log q_Z(Z) - \E_q\log q_\mu
        \\&amp;= \E_q\log p(Z|R,L,\mu) + \E_q\log \delta(X-\sum_k Z_k) + \E_q\log\frac{g_R}{q_R} + \E_q\log\frac{g_L}{q_L}+\E_q\log\frac{g_\mu}{q_\mu}-\E_q\log q_Z
        \\&amp;= \sum_k(\E_q\log p(Z_k|R_k,l_k,\mu_k)+\E_q\log\frac{g_{R_k}}{q_{R_k}}+\E_q\log\frac{g_{L_k}}{q_{L_k}}+\E_q\log\frac{g_{\mu_k}}{q_{\mu_k}})+ \E_q\log \delta(X-\sum_k Z_k)-\E_q\log q_Z.
\end{split}
\end{equation}\]</span></p>
<ol style="list-style-type: decimal">
<li>Update <span class="math inline">\(q_Z(Z)\)</span>: Take functional derivatives of the lower bound with respect to <span class="math inline">\(q_Z(Z)\)</span>, then <span class="math display">\[\begin{equation}
 \begin{split}
     q_Z(Z) &amp;\propto \exp (\int \int \log p(X,Z|R,L,\mu,g_R,g_L,g_\mu)q_R q_L q_\mu dR dLd\mu) 
     \\ &amp; \propto \exp(\int\int \log p(Z|X,R,\mu,L,g_R,g_L,g_\mu)q_Rq_L q_\mu dR dLd\mu)
     \\ &amp;\propto \exp (\E_{q_R,q_L,q_\mu}\log p(Z|X,R,L,\mu,g_R,g_L,g_\mu)).
 \end{split}
\end{equation}\]</span></li>
</ol>
<p>This leads to</p>
<p><span class="math display">\[q_Z(Z_{1:K,i,j})\sim Multinomial(X_{ij},\pi_{1:K,i,j}),\]</span> where <span class="math display">\[\pi_{k,i,j} = \frac{\exp(\E\log l_{ik}+\E\log f_{kj})}{\sum_k\exp(\E\log l_{ik}+\E\log f_{kj})},\]</span> <span class="math display">\[f_{kj} =  \mu_k\prod_{s=0}^{S-1} R_{k,s,s(j)}^{\epsilon_j(s)}(1-R_{k,s,s(j)})^{1-\epsilon_j(s)}.\]</span></p>
<p>The expectation <span class="math inline">\(\E\log f_{kj}\)</span> is then <span class="math display">\[\begin{equation}
\E\log f_{kj} = \E_{q_{\mu_k}}\log\mu_k + \sum_{s=0}^{S-1}\E_{R_{k,s}}({\epsilon_j(s)}\log R_{k,s,s(j)}+(1-\epsilon_j(s))\log(1-R_{k,s,s(j)})).
\end{equation}\]</span></p>
<p>From the ELBO formula (), updating distributions related to <span class="math inline">\(R,\mu,L\)</span> in rank-K problem reduces to solving K rank-1 problems.</p>
<ol start="2" style="list-style-type: decimal">
<li>Update <span class="math inline">\(q_{l_k}(\cdot)\)</span> and <span class="math inline">\(g_{l_k}(\cdot)\)</span>: <span class="math display">\[\begin{equation}
 \begin{split}
     q_L &amp;\propto \exp(\E_{q_R,q_\mu,q_Z}\log p(Z|L,R,\mu)p(L|g_L))
     \\&amp;\propto
     \exp(\sum_k(\E_q\log p(Z_k|L_k,R_k,\mu_k)p(L_k|g_{L_k}))).
 \end{split}
\end{equation}\]</span></li>
</ol>
<p>We update <span class="math inline">\(q_{l_k}\)</span> for each topic <span class="math inline">\(k\)</span>. The <span class="math inline">\(q_{l_k}\)</span> and <span class="math inline">\(g_{l_k}\)</span> can be updated by solving the following Empirical Bayes Poisson mean problem:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\sum_j \E_{q_Z}(Z_{k,i,j}) \sim Poisson (l_{ik}\sum_j \E_{q_{R_k},q_{\mu_k}}(f_{kj})),  i=1,2,...,N,
\\
\E_{q_{R_k},q_{\mu_k}}(f_{kj}) = \E_{q_{\mu_k}}\mu_k \times \prod_{s=0}^{S-1}\E_{R_{k,s}}(R_{k,s,s(j)}^{\epsilon_j(s)}(1-R_{k,s,s(j)})^{1-\epsilon_j(s)}),
\\
l_{k}\sim g_{l_k}(\cdot).
\end{split}
\end{equation}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Update <span class="math inline">\(q_{R_k}, q_{\mu_k},g_{R_k}, g_{\mu_k}\)</span>:</li>
</ol>
<p>Solve the following Empirical Bayes Multiscale Poisson Smoothing problem: given a Poisson sequence <span class="math inline">\(\sum_i\E_{q_Z}(Z_{k,i,j}), j=1,2,...,p\)</span> and an extra scale factor <span class="math inline">\(c = \sum_{i}E_{q_{l_k}}l_{ik}\)</span>.</p>

<ol style="list-style-type: decimal">
<li>Empirical Bayes Poisson Smoothing.</li>
</ol>
<p>We have at least two methods, all of which depend on the multiscale decomposition of Poisson sequence. The first one is the standard BMSM models in Kolaczyk(1999). Another one is in Xing et al(2019).</p>
<p>For <span class="math inline">\(\mu_k\)</span>, the simplest way is to set <span class="math inline">\(\hat{\mu}_k = \sum_i\sum_j\E_{q_Z}(Z_{k,i,j}) / \sum_i(l_{ik})\)</span>. This retains the property of preservation of energy and results in an estimate relatively unaffected by perturbations in the data at their original scale.</p>
<p>For <span class="math inline">\(R_{k,s}\)</span>, one way is to put a mixture of Beta distribution prior separately for each scale <span class="math display">\[R_{k,s,l}\sim \sum_h p_{k,s,h}Beta(\alpha_{k,s,h},\alpha_{k,s,h}).\]</span></p>
<p>To force smoothness in each <span class="math inline">\(f\)</span>, we can also put a point mass on <span class="math inline">\(\frac{1}{2}\)</span>. Another way is reparameterize <span class="math inline">\(R_{k,s,l}\)</span> to its logit form <span class="math inline">\(\log\frac{R_{k,s,l}}{1-R_{k,s,l}}\)</span>, then use normal approximation hence standard ash prior to achieve shrinkage estimate.</p>
<p>A common practice in wavelet shrinkage estimation is to use ‘cycle spinning’ or Non-decimated WT to get translation-invariant property.</p>
<p>To use the mixture of beta distribution, or more generally shrinking the probability directly, we need to develop Empirical Bayes Binomial probability .</p>

<p>Build code based on EBPMF implementations.</p>
<p>How to deal with many 0’s? Is zero-inflated model possible?</p>
<p>Run some simulation examples.</p>
<p>Potential applications.</p>
<p>Other modifications to the model</p>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
